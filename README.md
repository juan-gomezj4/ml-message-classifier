# Proyecto MLOps - ClasificaciÃ³n de Mensajes en Batch

La soluciÃ³n refleja un enfoque prÃ¡ctico -mantenible, reproducible y escalable- para implementar sistemas de ML en producciÃ³n, aplicando buenas prÃ¡cticas de MLOps desde la experimentaciÃ³n hasta el despliegue

El proyecto consiste en un sistema batch que automatiza la clasificaciÃ³n de mensajes enviados por usuarios a un canal de atenciÃ³n, simulados mediante reseÃ±as del **Yelp Open Dataset**. Se diseÃ±Ã³ una arquitectura modular basada en el enfoque **FTI (Feature - Training - Inference)**, con Ã©nfasis en mantenibilidad, reproducibilidad y escalabilidad

La implementaciÃ³n considera el ciclo completo: desde la ingesta de datos y procesamiento, hasta el entrenamiento, predicciÃ³n y activaciÃ³n de reentrenamiento bajo condiciones controladas

Este repositorio contiene todo el cÃ³digo, configuraciones y artefactos necesarios para replicar la soluciÃ³n

## **Objetivo**

El objetivo tÃ©cnico fue desarrollar un sistema de clasificaciÃ³n de mensajes en batch, alineado con principios de MLOps y capaz de escalar hacia entornos productivos

***La prioridad no estuvo en optimizar cada lÃ­nea de cÃ³digo***, sino en definir una **arquitectura clara**, una **lÃ³gica desacoplada entre etapas** y un flujo robusto de punta a punta. Se diseÃ±Ã³ una soluciÃ³n que refleja cÃ³mo se debe estructurar un sistema de ML real, mÃ¡s allÃ¡ de un simple modelo funcional

El proyecto priorizÃ³:

- **DiseÃ±ar pipelines desacoplados**, compatibles con ejecuciÃ³n secuencial o por orquestador
- **Definir pasos explÃ­citos por etapa** (extracciÃ³n, validaciÃ³n, agregaciÃ³n, etc.), facilitando la trazabilidad del flujo
- **Aplicar validaciones** de datos y modelos
- **Controlar dependencias y calidad del cÃ³digo** mediante herramientas como `uv`, `hydra`, `ruff`, `mypy`, `bandit`, `pre-commit`, `pytest` y `coverage.py`
- **Simular condiciones realistas de producciÃ³n**, incluyendo detecciÃ³n de drift, uso de feature store y reentrenamiento automÃ¡tico

Este enfoque permitiÃ³ construir un sistema sÃ³lido y extensible, listo para ser escalado o refactorizado sin comprometer su arquitectura base

## Arquitectura del sistema

La soluciÃ³n sigue la arquitectura FTI (Feature â†’ Training â†’ Inference), separando claramente la lÃ³gica de transformaciÃ³n, entrenamiento e inferencia. Cada etapa fue implementada como un pipeline independiente, permitiendo trazabilidad, reutilizaciÃ³n de componentes y mantenibilidad

El flujo completo tambiÃ©n contempla la lÃ³gica de reentrenamiento ante degradaciÃ³n del modelo

---

### ğŸŸ§ Feature Pipeline

Toma los datos crudos desde Yelp y los transforma en un conjunto de features limpios, validados y listos para modelar

Pasos implementados:
- `extract`: lectura de nuevos datos
- `remove duplicates`: eliminaciÃ³n de duplicados
- `validate`: validaciÃ³n de estructura y tipos
- `clean text`: preprocesamiento bÃ¡sico del texto
- `create new features`: variables derivadas
- `embedding`: transformaciÃ³n del texto en vectores numÃ©ricos

[ğŸ“ Ver Feature Pipeline Scikit-learn](https://htmlpreview.github.io/?https://github.com/juan-gomezj4/ml-message-classifier/blob/main/data/08_reporting/feature_pipeline.html)

---

### ğŸŸ© Training Pipeline

Utiliza los datos procesados para generar un modelo entrenado. Mantiene consistencia entre entrenamiento y validaciÃ³n, asegurando que las transformaciones aplicadas en producciÃ³n sean equivalentes

Pasos implementados:
- `imputer`: imputaciÃ³n de valores nulos
- `encoding`: codificaciÃ³n de variables
- `scaler`: escalado de variables numÃ©ricas
- `dimensionality reducer`: reducciÃ³n opcional de dimensionalidad
- `training`: entrenamiento del modelo
- `validate`: evaluaciÃ³n con mÃ©tricas definidas

[ğŸ“ Ver Training Pipeline Scikit-learn](https://htmlpreview.github.io/?https://github.com/juan-gomezj4/ml-message-classifier/blob/main/data/08_reporting/training_pipeline.html)

---

### ğŸŸ¦ Inference Pipeline

Aplica el modelo entrenado sobre nuevos datos manteniendo la misma lÃ³gica de transformaciÃ³n que en el entrenamiento

Pasos implementados:
- Repite el mismo flujo de Feature Pipeline para nuevos datos
- Carga el `Pipeline Trainer` con los artefactos del modelo
- Aplica `predict` y entrega resultados listos para gestiÃ³n operativa



---

### ğŸ” LÃ³gica de reentrenamiento (CT)

El sistema activa el reentrenamiento automÃ¡tico cuando se detecta sesgo en las predicciones (por ejemplo, si cualquier clase predicha representa menos del 10% o mÃ¡s del 90% del total). En ese caso:

- Se extraen nuevos datos

- Se ejecuta nuevamente el Feature Pipeline

- Se actualiza el modelo usando el mismo algoritmo y configuraciÃ³n actual (no se ajustan hiperparÃ¡metros)

- El Pipeline Trainer es reescrito con los nuevos datos

Este proceso permite mantener el modelo actualizado ante cambios en la distribuciÃ³n de los datos sin modificar su estructura base

## Diccionario de datos

Para esta soluciÃ³n se utilizÃ³ el Yelp Open Dataset como simulaciÃ³n de mensajes enviados por usuarios a un canal de atenciÃ³n. A partir de este conjunto se estructuraron las tablas base que alimentan el pipeline

### ğŸ§‘â€ğŸ’¼ Tabla: `user`

| Campo                  | Tipo     | DescripciÃ³n                                                                 |
|------------------------|----------|-----------------------------------------------------------------------------|
| `user_id`              | string   | ID Ãºnico del usuario                                                        |
| `name`                 | string   | Nombre del usuario                                                          |
| `review_count`         | int      | NÃºmero total de reseÃ±as escritas                                           |
| `yelping_since`        | string   | Fecha en que se uniÃ³ a Yelp (AAAA-MM-DD)                                   |
| `useful`               | int      | Votos 'useful' recibidos                                                    |
| `funny`                | int      | Votos 'funny' recibidos                                                     |
| `cool`                 | int      | Votos 'cool' recibidos                                                      |
| `elite`                | string   | AÃ±os como usuario elite (separados por coma o vacÃ­o)                        |
| `friends`              | string   | Lista de IDs de amigos (separados por coma o vacÃ­o)                         |
| `fans`                 | int      | NÃºmero de seguidores                                                        |
| `average_stars`        | float    | Promedio de estrellas que ha dado                                           |

---

### ğŸ¢ Tabla: `business`

| Campo           | Tipo     | DescripciÃ³n                                               |
|-----------------|----------|-----------------------------------------------------------|
| `business_id`   | string   | ID Ãºnico del negocio                                      |
| `name`          | string   | Nombre del negocio                                        |
| `address`       | string   | DirecciÃ³n                                                 |
| `city`          | string   | Ciudad                                                    |
| `state`         | string   | Estado o regiÃ³n                                           |
| `postal_code`   | string   | CÃ³digo postal                                             |
| `latitude`      | float    | Latitud geogrÃ¡fica                                        |
| `longitude`     | float    | Longitud geogrÃ¡fica                                       |
| `stars`         | float    | Promedio de estrellas recibido                           |
| `review_count`  | int      | NÃºmero total de reseÃ±as recibidas                        |
| `is_open`       | int      | Indicador de si el negocio estÃ¡ abierto (1) o cerrado (0)|
| `attributes`    | string   | InformaciÃ³n adicional sobre el negocio (JSON u objeto)   |
| `categories`    | string   | CategorÃ­as a las que pertenece el negocio                |
| `hours`         | string   | Horario de atenciÃ³n (JSON u objeto)                      |

---

### ğŸ“ Tabla: `review`

| Campo         | Tipo        | DescripciÃ³n                                                        |
|---------------|-------------|--------------------------------------------------------------------|
| `review_id`   | string      | ID Ãºnico de la reseÃ±a                                              |
| `user_id`     | string      | ID del usuario que hizo la reseÃ±a (relaciÃ³n con `user.user_id`)    |
| `business_id` | string      | ID del negocio reseÃ±ado (relaciÃ³n con `business.business_id`)      |
| `stars`       | int         | CalificaciÃ³n en estrellas dada por el usuario                      |
| `useful`      | int         | Votos 'useful' que recibiÃ³ la reseÃ±a                               |
| `funny`       | int         | Votos 'funny' que recibiÃ³ la reseÃ±a                                |
| `cool`        | int         | Votos 'cool' que recibiÃ³ la reseÃ±a                                 |
| `text`        | string      | Texto completo de la reseÃ±a                                        |
| `date`        | datetime    | Fecha en que se escribiÃ³ la reseÃ±a                                 |


## Decisiones tÃ©cnicas

Durante el desarrollo del sistema se tomaron decisiones centradas en una soluciÃ³n reproducible, mantenible, escalable  y criterios reales de ingenierÃ­a, mÃ¡s allÃ¡ de la construcciÃ³n de un modelo puntual. A continuaciÃ³n, se describen los principales puntos tÃ©cnicos:

---

### ğŸ”¨ Modularidad y diseÃ±o de pipelines

- Se definiÃ³ una arquitectura **FTI (Feature - Training - Inference)** que permite separar responsabilidades y facilita testing, mantenimiento y reusabilidad.
- Cada pipeline estÃ¡ desacoplado y puede ejecutarse en forma independiente o como parte de un flujo orquestado

---

### ğŸ§  Feature Store

- Se implementÃ³ una estructura que permite reutilizar las features generadas entre entrenamiento e inferencia
- Esto asegura coherencia en la transformaciÃ³n y reduce tiempos de cÃ³mputo en producciÃ³n

---

### ğŸ“¦ Entorno y gestiÃ³n de dependencias

- Se utilizÃ³ `uv` para garantizar entornos reproducibles, ligeros y aislados.
- La configuraciÃ³n del proyecto se gestiona con `hydra`, evitando hardcoding y facilitando la parametrizaciÃ³n de pipelines

---

### ğŸ§ª ValidaciÃ³n y calidad del cÃ³digo

- Se integraron `pre-commit` hooks para asegurar validaciones constantes sobre el cÃ³digo
- Uso de `ruff` (linter + formatter), `mypy` (tipado estÃ¡tico) y `bandit` (seguridad)
- Validaciones de datos estructurales
- Testing funcional cubierto con `pytest`, con tracking de cobertura (`coverage.py`)

---

### ğŸ§¬ SelecciÃ³n de variables

Para reducir la dimensionalidad y evitar ruido, se implementÃ³ un pipeline especÃ­fico que incluye:

- EliminaciÃ³n de variables constantes
- EliminaciÃ³n de variables altamente correlacionadas
- SelecciÃ³n de variables basadas en importancia usando un Random Forest

Esto permitiÃ³ construir un conjunto de features compacto y relevante, manteniendo la interpretabilidad del modelo

---

### ğŸ¯ ConstrucciÃ³n de la variable objetivo y mÃ©trica seleccionada

Se tratÃ³ como un problema de clasificaciÃ³n multiclase, donde la variable objetivo fue construida a partir de las estrellas de calificaciÃ³n de la reseÃ±a (`stars`) del dataset de Yelp:

- `0` â†’ calificaciones menores o iguales a 2
- `1` â†’ calificaciones de 3
- `2` â†’ calificaciones de 4 o 5

Dado que no se aplicÃ³ balanceo de clases y se buscaba una mÃ©trica robusta ante desbalance, se utilizÃ³ **F1-score ponderado (`f1_weighted`)** para la selecciÃ³n del modelo final

---

### âš™ï¸ Modelado y experimentaciÃ³n

- No se aplicÃ³ un benchmark exhaustivo, pero se probaron mÃºltiples algoritmos incluyendo AutoML.
- El mejor modelo fue seleccionado por desempeÃ±o base y luego afinado con `GridSearchCV`
- El foco no estuvo en optimizaciÃ³n algorÃ­tmica, sino en asegurar un sistema replicable y extensible

---

### ğŸ”„ Coherencia entre entrenamiento e inferencia

Se garantizÃ³ la coherencia entre etapas identificando claramente las responsabilidades de cada una, definiendo su orden en un diagrama general de soluciÃ³n, y encapsulando la lÃ³gica dentro de `PipelineTrainer`. Esto asegura que el flujo de transformaciÃ³n en inferencia sea equivalente al usado durante el entrenamiento

---

### âœ… ValidaciÃ³n del flujo end-to-end

Aunque se trata de un proyecto de prueba tÃ©cnica, se implementaron estrategias reales para asegurar trazabilidad:

- Cada paso del Feature Pipeline guarda una versiÃ³n intermedia de los datos para su inspecciÃ³n
- Se incluyeron `loggers` en todo el flujo para facilitar seguimiento y debugging
- Se probaron corridas con subconjuntos pequeÃ±os (1.000â€“2.000 registros) para validar la lÃ³gica general antes de escalar
- El desarrollo partiÃ³ de una versiÃ³n bÃ¡sica en notebooks, sin clases, que permitiÃ³ validar la idea general antes de modularizar

---

### â˜ï¸ PreparaciÃ³n para producciÃ³n

- Aunque el flujo fue probado localmente, se definieron componentes para despliegue en AWS (Glue, Step Functions, S3, Lambda).
- Se estableciÃ³ una estrategia de monitoreo basada en mÃ©tricas clave del flujo y del modelo.
- Se propuso la integraciÃ³n con SNS para alertas y Lambda para ejecuciÃ³n automÃ¡tica ante errores o drift.

## Estructura del proyecto

La organizaciÃ³n del repositorio sigue principios de separaciÃ³n de responsabilidades, modularidad y trazabilidad. A continuaciÃ³n se describe la estructura principal:
```
â”œâ”€â”€ conf/                           # ConfiguraciÃ³n del proyecto por etapa (feature, training, inference)
â”‚   â”œâ”€â”€ data_feature/
â”‚   â”œâ”€â”€ model_inference/
â”‚   â””â”€â”€ model_training/
â”‚
â”œâ”€â”€ data/                           # Capas de datos segÃºn el flujo FTI
â”‚   â”œâ”€â”€ 01_raw/                     # Archivos originales del dataset (Yelp)
â”‚   â”œâ”€â”€ 02_intermediate/           # Datos validados
â”‚   â”œâ”€â”€ 03_primary/                # Datos agregados y comprimidos
â”‚   â”œâ”€â”€ 04_feature/                # Dataset final con features (MIT)
â”‚   â”œâ”€â”€ 05_model_input/            # Dataset listo para modelado
â”‚   â”œâ”€â”€ 06_models/                 # ParÃ¡metros y metadata del mejor modelo
â”‚   â”œâ”€â”€ 07_model_output/           # Resultados de predicciÃ³n
â”‚   â”œâ”€â”€ 08_reporting/              # MÃ©tricas y visualizaciones
â”‚   â””â”€â”€ 09_inference/              # Datos de entrada/salida para inferencia
â”‚
â”œâ”€â”€ docs/                          # DocumentaciÃ³n en formato Markdown
â”‚
â”œâ”€â”€ models/                        # Artefactos del modelo serializado (.pkl)
â”‚
â”œâ”€â”€ notebooks/                     # ExploraciÃ³n, experimentaciÃ³n y pruebas manuales
â”‚
â”œâ”€â”€ src/                           # CÃ³digo fuente modular del proyecto
â”‚   â”œâ”€â”€ data/                      # MÃ³dulos para extracciÃ³n, validaciÃ³n, agregaciÃ³n, etc.
â”‚   â”œâ”€â”€ inference/                 # LÃ³gica de inferencia y carga del modelo
â”‚   â”œâ”€â”€ model/                     # Entrenamiento, transformaciÃ³n y validaciÃ³n del modelo
â”‚   â”œâ”€â”€ pipelines/                # DefiniciÃ³n de los pipelines FTI
â”‚   â”‚   â”œâ”€â”€ feature_pipeline/
â”‚   â”‚   â”œâ”€â”€ training_pipeline/
â”‚   â”‚   â””â”€â”€ inference_pipeline/
â”‚
â”œâ”€â”€ tests/                         # Estructura bÃ¡sica para pruebas por componente
â”‚
â”œâ”€â”€ start_batch_nlp.py            # Script principal para ejecutar el sistema
â”œâ”€â”€ Makefile                      # Comandos automatizados (ej. test, lint, run)
â”œâ”€â”€ pyproject.toml                # ConfiguraciÃ³n general del proyecto (mypy, ruff, etc.)
â”œâ”€â”€ uv.lock                       # Lockfile para gestiÃ³n de dependencias con uv
â”œâ”€â”€ codecov.yml                   # ConfiguraciÃ³n de cobertura de cÃ³digo
â””â”€â”€ README.md                     # Documento principal del proyecto
```

## ğŸ§ª CI / ğŸš€ CD  

El proyecto implementa un flujo completo y funcional de MLOps:

### âœ… CI â€“ Continuous Integration

- ValidaciÃ³n automÃ¡tica de estilo, tipos y errores con `pre-commit`, `ruff` y `mypy`
- Pruebas unitarias con `pytest` y cobertura de cÃ³digo, integradas en GitHub Actions.
- Reporte de coverage enviado a [Codecov](https://about.codecov.io/)

### ğŸš€ CD â€“ Continuous Delivery

- Entrenamiento del modelo desde datos preprocesados (`data/04_feature/review_user_business_mit_sample.parquet`).
- Pipeline modular usando `sklearn.Pipeline`, compuesto por:
  - `MDTYelpData`: transformaciones dependientes del modelo.
  - `TrainModelTransformer`: entrenamiento con `XGBClassifier`.
- IntegraciÃ³n en el CI/CD con el comando `make train`, ejecutado automÃ¡ticamente tras pasar los tests.


## Siguientes pasos tÃ©cnicos

Este MVP deja sentada la arquitectura base del sistema, pero se identificaron varias oportunidades de mejora para la siguiente iteraciÃ³n:

- ğŸ§¼ **Refactor del cÃ³digo**  
  Reorganizar y simplificar transformadores, funciones y clases para mayor legibilidad y mantenimiento

- ğŸ§ª **RevisiÃ³n de tipado estÃ¡tico**  
  Ajustar las anotaciones de tipo (`mypy`) en transformadores, funciones y clases para mejorar validaciÃ³n en desarrollo

- âš–ï¸ **Balanceo de clases**  
  Evaluar tÃ©cnicas como reponderaciÃ³n o submuestreo para mejorar el rendimiento del modelo en clases minoritarias

- ğŸ§  **Interpretabilidad del modelo**  
  Incluir anÃ¡lisis de importancia de variables (`feature_importance_`) y herramientas como SHAP para explicar predicciones

- ğŸ“ˆ **OptimizaciÃ³n del rendimiento**  
  La mÃ©trica `f1_macro` pasÃ³ de **0.63 a 0.70** tras ajustes simples; nuevas mejoras podrÃ­an llevarla mÃ¡s lejos con balanceo e interpretabilidad

Estas mejoras son compatibles con la arquitectura actual y se pueden incorporar sin romper el diseÃ±o del sistema
