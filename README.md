# Proyecto MLOps - Clasificaci√≥n de Mensajes en Batch

La soluci√≥n refleja un enfoque pr√°ctico -mantenible, reproducible y escalable- para implementar sistemas de ML en producci√≥n, aplicando buenas pr√°cticas de MLOps desde la experimentaci√≥n hasta el despliegue

El proyecto consiste en un sistema batch que automatiza la clasificaci√≥n de mensajes enviados por usuarios a un canal de atenci√≥n, simulados mediante rese√±as del **Yelp Open Dataset**. Se dise√±√≥ una arquitectura modular basada en el enfoque **FTI (Feature - Training - Inference)**, con √©nfasis en mantenibilidad, reproducibilidad y escalabilidad

La implementaci√≥n considera el ciclo completo: desde la ingesta de datos y procesamiento, hasta el entrenamiento, predicci√≥n y activaci√≥n de reentrenamiento bajo condiciones controladas

Este repositorio contiene todo el c√≥digo, configuraciones y artefactos necesarios para replicar la soluci√≥n

## **Objetivo**

El objetivo t√©cnico fue desarrollar un sistema de clasificaci√≥n de mensajes en batch, alineado con principios de MLOps y capaz de escalar hacia entornos productivos

***La prioridad no estuvo en optimizar cada l√≠nea de c√≥digo***, sino en definir una **arquitectura clara**, una **l√≥gica desacoplada entre etapas** y un flujo robusto de punta a punta. Se dise√±√≥ una soluci√≥n que refleja c√≥mo se debe estructurar un sistema de ML real, m√°s all√° de un simple modelo funcional

El proyecto prioriz√≥:

- **Dise√±ar pipelines desacoplados**, compatibles con ejecuci√≥n secuencial o por orquestador
- **Definir pasos expl√≠citos por etapa** (extracci√≥n, validaci√≥n, agregaci√≥n, etc.), facilitando la trazabilidad del flujo
- **Aplicar validaciones** de datos y modelos
- **Controlar dependencias y calidad del c√≥digo** mediante herramientas como `uv`, `hydra`, `ruff`, `mypy`, `bandit`, `pre-commit`, `pytest` y `coverage.py`
- **Simular condiciones realistas de producci√≥n**, incluyendo detecci√≥n de drift, uso de feature store y reentrenamiento autom√°tico

Este enfoque permiti√≥ construir un sistema s√≥lido y extensible, listo para ser escalado o refactorizado sin comprometer su arquitectura base

## Arquitectura del sistema

La soluci√≥n sigue la arquitectura FTI (Feature ‚Üí Training ‚Üí Inference), separando claramente la l√≥gica de transformaci√≥n, entrenamiento e inferencia. Cada etapa fue implementada como un pipeline independiente, permitiendo trazabilidad, reutilizaci√≥n de componentes y mantenibilidad

El flujo completo tambi√©n contempla la l√≥gica de reentrenamiento ante degradaci√≥n del modelo

---

### üüß Feature Pipeline

Toma los datos crudos desde Yelp y los transforma en un conjunto de features limpios, validados y listos para modelar

Pasos implementados:
- `extract`: lectura de nuevos datos
- `remove duplicates`: eliminaci√≥n de duplicados
- `validate`: validaci√≥n de estructura y tipos
- `clean text`: preprocesamiento b√°sico del texto
- `create new features`: variables derivadas
- `embedding`: transformaci√≥n del texto en vectores num√©ricos

[üìé Ver Feature Pipeline Scikit-learn](https://htmlpreview.github.io/?https://github.com/juan-gomezj4/ml-message-classifier/blob/main/data/08_reporting/feature_pipeline.html)

---

### üü© Training Pipeline

Utiliza los datos procesados para generar un modelo entrenado. Mantiene consistencia entre entrenamiento y validaci√≥n, asegurando que las transformaciones aplicadas en producci√≥n sean equivalentes

Pasos implementados:
- `imputer`: imputaci√≥n de valores nulos
- `encoding`: codificaci√≥n de variables
- `scaler`: escalado de variables num√©ricas
- `dimensionality reducer`: reducci√≥n opcional de dimensionalidad
- `training`: entrenamiento del modelo
- `validate`: evaluaci√≥n con m√©tricas definidas

[üìé Ver Training Pipeline Scikit-learn](https://htmlpreview.github.io/?https://github.com/juan-gomezj4/ml-message-classifier/blob/main/data/08_reporting/training_pipeline.html)

---

### üü¶ Inference Pipeline

Aplica el modelo entrenado sobre nuevos datos manteniendo la misma l√≥gica de transformaci√≥n que en el entrenamiento

Pasos implementados:
- Repite el mismo flujo de Feature Pipeline para nuevos datos
- Carga el `Pipeline Trainer` con los artefactos del modelo
- Aplica `predict` y entrega resultados listos para gesti√≥n operativa



---

### üîÅ L√≥gica de reentrenamiento (CT)

El sistema activa el reentrenamiento autom√°tico cuando se detecta sesgo en las predicciones (por ejemplo, si cualquier clase predicha representa menos del 10% o m√°s del 90% del total). En ese caso:

- Se extraen nuevos datos

- Se ejecuta nuevamente el Feature Pipeline

- Se actualiza el modelo usando el mismo algoritmo y configuraci√≥n actual (no se ajustan hiperpar√°metros)

- El Pipeline Trainer es reescrito con los nuevos datos

Este proceso permite mantener el modelo actualizado ante cambios en la distribuci√≥n de los datos sin modificar su estructura base

## Diccionario de datos

Para esta soluci√≥n se utiliz√≥ el Yelp Open Dataset como simulaci√≥n de mensajes enviados por usuarios a un canal de atenci√≥n. A partir de este conjunto se estructuraron las tablas base que alimentan el pipeline

### üßë‚Äçüíº Tabla: `user`

| Campo                  | Tipo     | Descripci√≥n                                                                 |
|------------------------|----------|-----------------------------------------------------------------------------|
| `user_id`              | string   | ID √∫nico del usuario                                                        |
| `name`                 | string   | Nombre del usuario                                                          |
| `review_count`         | int      | N√∫mero total de rese√±as escritas                                           |
| `yelping_since`        | string   | Fecha en que se uni√≥ a Yelp (AAAA-MM-DD)                                   |
| `useful`               | int      | Votos 'useful' recibidos                                                    |
| `funny`                | int      | Votos 'funny' recibidos                                                     |
| `cool`                 | int      | Votos 'cool' recibidos                                                      |
| `elite`                | string   | A√±os como usuario elite (separados por coma o vac√≠o)                        |
| `friends`              | string   | Lista de IDs de amigos (separados por coma o vac√≠o)                         |
| `fans`                 | int      | N√∫mero de seguidores                                                        |
| `average_stars`        | float    | Promedio de estrellas que ha dado                                           |

---

### üè¢ Tabla: `business`

| Campo           | Tipo     | Descripci√≥n                                               |
|-----------------|----------|-----------------------------------------------------------|
| `business_id`   | string   | ID √∫nico del negocio                                      |
| `name`          | string   | Nombre del negocio                                        |
| `address`       | string   | Direcci√≥n                                                 |
| `city`          | string   | Ciudad                                                    |
| `state`         | string   | Estado o regi√≥n                                           |
| `postal_code`   | string   | C√≥digo postal                                             |
| `latitude`      | float    | Latitud geogr√°fica                                        |
| `longitude`     | float    | Longitud geogr√°fica                                       |
| `stars`         | float    | Promedio de estrellas recibido                           |
| `review_count`  | int      | N√∫mero total de rese√±as recibidas                        |
| `is_open`       | int      | Indicador de si el negocio est√° abierto (1) o cerrado (0)|
| `attributes`    | string   | Informaci√≥n adicional sobre el negocio (JSON u objeto)   |
| `categories`    | string   | Categor√≠as a las que pertenece el negocio                |
| `hours`         | string   | Horario de atenci√≥n (JSON u objeto)                      |

---

### üìù Tabla: `review`

| Campo         | Tipo        | Descripci√≥n                                                        |
|---------------|-------------|--------------------------------------------------------------------|
| `review_id`   | string      | ID √∫nico de la rese√±a                                              |
| `user_id`     | string      | ID del usuario que hizo la rese√±a (relaci√≥n con `user.user_id`)    |
| `business_id` | string      | ID del negocio rese√±ado (relaci√≥n con `business.business_id`)      |
| `stars`       | int         | Calificaci√≥n en estrellas dada por el usuario                      |
| `useful`      | int         | Votos 'useful' que recibi√≥ la rese√±a                               |
| `funny`       | int         | Votos 'funny' que recibi√≥ la rese√±a                                |
| `cool`        | int         | Votos 'cool' que recibi√≥ la rese√±a                                 |
| `text`        | string      | Texto completo de la rese√±a                                        |
| `date`        | datetime    | Fecha en que se escribi√≥ la rese√±a                                 |


## Decisiones t√©cnicas

Durante el desarrollo del sistema se tomaron decisiones centradas en una soluci√≥n reproducible, mantenible, escalable  y criterios reales de ingenier√≠a, m√°s all√° de la construcci√≥n de un modelo puntual. A continuaci√≥n, se describen los principales puntos t√©cnicos:

---

### üî® Modularidad y dise√±o de pipelines

- Se defini√≥ una arquitectura **FTI (Feature - Training - Inference)** que permite separar responsabilidades y facilita testing, mantenimiento y reusabilidad.
- Cada pipeline est√° desacoplado y puede ejecutarse en forma independiente o como parte de un flujo orquestado

---

### üß† Feature Store

- Se implement√≥ una estructura que permite reutilizar las features generadas entre entrenamiento e inferencia
- Esto asegura coherencia en la transformaci√≥n y reduce tiempos de c√≥mputo en producci√≥n

---

### üì¶ Entorno y gesti√≥n de dependencias

- Se utiliz√≥ `uv` para garantizar entornos reproducibles, ligeros y aislados.
- La configuraci√≥n del proyecto se gestiona con `hydra`, evitando hardcoding y facilitando la parametrizaci√≥n de pipelines

---

### üß™ Validaci√≥n y calidad del c√≥digo

- Se integraron `pre-commit` hooks para asegurar validaciones constantes sobre el c√≥digo
- Uso de `ruff` (linter + formatter), `mypy` (tipado est√°tico) y `bandit` (seguridad)
- Validaciones de datos estructurales
- Testing funcional cubierto con `pytest`, con tracking de cobertura (`coverage.py`)

---

### üß¨ Selecci√≥n de variables

Para reducir la dimensionalidad y evitar ruido, se implement√≥ un pipeline espec√≠fico que incluye:

- Eliminaci√≥n de variables constantes
- Eliminaci√≥n de variables altamente correlacionadas
- Selecci√≥n de variables basadas en importancia usando un Random Forest

Esto permiti√≥ construir un conjunto de features compacto y relevante, manteniendo la interpretabilidad del modelo

---

### üéØ Construcci√≥n de la variable objetivo y m√©trica seleccionada

Se trat√≥ como un problema de clasificaci√≥n multiclase, donde la variable objetivo fue construida a partir de las estrellas de calificaci√≥n de la rese√±a (`stars`) del dataset de Yelp:

- `0` ‚Üí calificaciones menores o iguales a 2
- `1` ‚Üí calificaciones de 3
- `2` ‚Üí calificaciones de 4 o 5

Dado que no se aplic√≥ balanceo de clases y se buscaba una m√©trica robusta ante desbalance, se utiliz√≥ **F1-score ponderado (`f1_weighted`)** para la selecci√≥n del modelo final

---

### ‚öôÔ∏è Modelado y experimentaci√≥n

- No se aplic√≥ un benchmark exhaustivo, pero se probaron m√∫ltiples algoritmos incluyendo AutoML.
- El mejor modelo fue seleccionado por desempe√±o base y luego afinado con `GridSearchCV`
- El foco no estuvo en optimizaci√≥n algor√≠tmica, sino en asegurar un sistema replicable y extensible

---

### üîÑ Coherencia entre entrenamiento e inferencia

Se garantiz√≥ la coherencia entre etapas identificando claramente las responsabilidades de cada una, definiendo su orden en un diagrama general de soluci√≥n, y encapsulando la l√≥gica dentro de `PipelineTrainer`. Esto asegura que el flujo de transformaci√≥n en inferencia sea equivalente al usado durante el entrenamiento

---

### ‚úÖ Validaci√≥n del flujo end-to-end

Aunque se trata de un proyecto de prueba t√©cnica, se implementaron estrategias reales para asegurar trazabilidad:

- Cada paso del Feature Pipeline guarda una versi√≥n intermedia de los datos para su inspecci√≥n
- Se incluyeron `loggers` en todo el flujo para facilitar seguimiento y debugging
- Se probaron corridas con subconjuntos peque√±os (1.000‚Äì2.000 registros) para validar la l√≥gica general antes de escalar
- El desarrollo parti√≥ de una versi√≥n b√°sica en notebooks, sin clases, que permiti√≥ validar la idea general antes de modularizar

---

### ‚òÅÔ∏è Preparaci√≥n para producci√≥n

- Aunque el flujo fue probado localmente, se definieron componentes para despliegue en AWS (Glue, Step Functions, S3, Lambda).
- Se estableci√≥ una estrategia de monitoreo basada en m√©tricas clave del flujo y del modelo.
- Se propuso la integraci√≥n con SNS para alertas y Lambda para ejecuci√≥n autom√°tica ante errores o drift.

## Estructura del proyecto

La organizaci√≥n del repositorio sigue principios de separaci√≥n de responsabilidades, modularidad y trazabilidad. A continuaci√≥n se describe la estructura principal:
```
‚îú‚îÄ‚îÄ conf/                           # Configuraci√≥n del proyecto por etapa (feature, training, inference)
‚îÇ   ‚îú‚îÄ‚îÄ data_feature/
‚îÇ   ‚îú‚îÄ‚îÄ model_inference/
‚îÇ   ‚îî‚îÄ‚îÄ model_training/
‚îÇ
‚îú‚îÄ‚îÄ data/                           # Capas de datos seg√∫n el flujo FTI
‚îÇ   ‚îú‚îÄ‚îÄ 01_raw/                     # Archivos originales del dataset (Yelp)
‚îÇ   ‚îú‚îÄ‚îÄ 02_intermediate/           # Datos validados
‚îÇ   ‚îú‚îÄ‚îÄ 03_primary/                # Datos agregados y comprimidos
‚îÇ   ‚îú‚îÄ‚îÄ 04_feature/                # Dataset final con features (MIT)
‚îÇ   ‚îú‚îÄ‚îÄ 05_model_input/            # Dataset listo para modelado
‚îÇ   ‚îú‚îÄ‚îÄ 06_models/                 # Par√°metros y metadata del mejor modelo
‚îÇ   ‚îú‚îÄ‚îÄ 07_model_output/           # Resultados de predicci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ 08_reporting/              # M√©tricas y visualizaciones
‚îÇ   ‚îî‚îÄ‚îÄ 09_inference/              # Datos de entrada/salida para inferencia
‚îÇ
‚îú‚îÄ‚îÄ docs/                          # Documentaci√≥n en formato Markdown
‚îÇ
‚îú‚îÄ‚îÄ models/                        # Artefactos del modelo serializado (.pkl)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                     # Exploraci√≥n, experimentaci√≥n y pruebas manuales
‚îÇ
‚îú‚îÄ‚îÄ src/                           # C√≥digo fuente modular del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ data/                      # M√≥dulos para extracci√≥n, validaci√≥n, agregaci√≥n, etc.
‚îÇ   ‚îú‚îÄ‚îÄ inference/                 # L√≥gica de inferencia y carga del modelo
‚îÇ   ‚îú‚îÄ‚îÄ model/                     # Entrenamiento, transformaci√≥n y validaci√≥n del modelo
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/                # Definici√≥n de los pipelines FTI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_pipeline/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_pipeline/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference_pipeline/
‚îÇ
‚îú‚îÄ‚îÄ tests/                         # Estructura b√°sica para pruebas por componente
‚îÇ
‚îú‚îÄ‚îÄ start_batch_nlp.py            # Script principal para ejecutar el sistema
‚îú‚îÄ‚îÄ Makefile                      # Comandos automatizados (ej. test, lint, run)
‚îú‚îÄ‚îÄ pyproject.toml                # Configuraci√≥n general del proyecto (mypy, ruff, etc.)
‚îú‚îÄ‚îÄ uv.lock                       # Lockfile para gesti√≥n de dependencias con uv
‚îú‚îÄ‚îÄ codecov.yml                   # Configuraci√≥n de cobertura de c√≥digo
‚îî‚îÄ‚îÄ README.md                     # Documento principal del proyecto
```

## üß™ CI / üöÄ CD  

El proyecto implementa un flujo completo y funcional de MLOps:

### ‚úÖ CI ‚Äì Continuous Integration

- Validaci√≥n autom√°tica de estilo, tipos y errores con `pre-commit`, `ruff` y `mypy`
- Pruebas unitarias con `pytest` y cobertura de c√≥digo, integradas en GitHub Actions.
- Reporte de coverage enviado a [Codecov](https://about.codecov.io/)

### üöÄ CD ‚Äì Continuous Delivery

- Entrenamiento del modelo desde datos preprocesados (`data/04_feature/review_user_business_mit_sample.parquet`).
- Pipeline modular usando `sklearn.Pipeline`, compuesto por:
  - `MDTYelpData`: transformaciones dependientes del modelo.
  - `TrainModelTransformer`: entrenamiento con `XGBClassifier`.
- Integraci√≥n en el CI/CD con el comando `make train`, ejecutado autom√°ticamente tras pasar los tests.


## Siguientes pasos t√©cnicos

Este MVP deja sentada la arquitectura base del sistema, pero se identificaron varias oportunidades de mejora para la siguiente iteraci√≥n:

- üßº **Refactor del c√≥digo**  
  Reorganizar y simplificar transformadores, funciones y clases para mayor legibilidad y mantenimiento

- üß™ **Revisi√≥n de tipado est√°tico**  
  Ajustar las anotaciones de tipo (`mypy`) en transformadores, funciones y clases para mejorar validaci√≥n en desarrollo

- ‚öñÔ∏è **Balanceo de clases**  
  Evaluar t√©cnicas como reponderaci√≥n o submuestreo para mejorar el rendimiento del modelo en clases minoritarias

- üß† **Interpretabilidad del modelo**  
  Incluir an√°lisis de importancia de variables (`feature_importance_`) y herramientas como SHAP para explicar predicciones

- üìà **Optimizaci√≥n del rendimiento**  
  La m√©trica `f1_macro` pas√≥ de **0.63 a 0.70** tras ajustes simples; nuevas mejoras podr√≠an llevarla m√°s lejos con balanceo e interpretabilidad

Estas mejoras son compatibles con la arquitectura actual y se pueden incorporar sin romper el dise√±o del sistema
