{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJO4nq-rjOVi"
   },
   "source": [
    "## Title\n",
    "Models\n",
    "\n",
    "### By:\n",
    "Juan GÃ³mez\n",
    "\n",
    "### Date:\n",
    "2024-05-18\n",
    "\n",
    "### Description:\n",
    "\n",
    "Train and evaluate text classification models using preprocessed features. Includes data split, cross-validation, performance metrics, learning curves, scalability plots, and feature importance analysis. Final section builds the MDT and training prediction pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUF5E1QMjOVk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import  libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "M2QetAMAjOVk",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from feature_engine.selection import (\n",
    "    DropConstantFeatures,\n",
    "    DropCorrelatedFeatures,\n",
    "    SelectBySingleFeaturePerformance,\n",
    ")\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler, OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U_3Omo9jOVk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LxgbCbmwjOVl"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "BASE_DIR = Path.cwd().resolve().parents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "id": "1uqUhdiAjOVl",
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(BASE_DIR / \"data/04_feature/review_user_business_mit.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "wB6XLEUAmgxy",
    "outputId": "6e4ba660-f5be-4098-d616-bcaaba52a5e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_agg__elite_count</th>\n",
       "      <th>cat_agg__city_freq</th>\n",
       "      <th>cat_agg__state_freq</th>\n",
       "      <th>num_agg__useful</th>\n",
       "      <th>num_agg__funny</th>\n",
       "      <th>num_agg__cool</th>\n",
       "      <th>num_agg__review_count</th>\n",
       "      <th>num_agg__is_useful</th>\n",
       "      <th>num_agg__is_funny</th>\n",
       "      <th>num_agg__is_cool</th>\n",
       "      <th>num_agg__review_count_level</th>\n",
       "      <th>num_agg__useful_user_level</th>\n",
       "      <th>num_agg__funny_user_level</th>\n",
       "      <th>num_agg__cool_user_level</th>\n",
       "      <th>num_agg__fans_level</th>\n",
       "      <th>str_agg__text_length</th>\n",
       "      <th>str_agg__word_count</th>\n",
       "      <th>str_agg__has_exclamation</th>\n",
       "      <th>str_agg__main_category_group</th>\n",
       "      <th>str_agg__category_count</th>\n",
       "      <th>date_agg__review_year</th>\n",
       "      <th>date_agg__review_month</th>\n",
       "      <th>date_agg__review_dayofweek</th>\n",
       "      <th>date_agg__is_weekend</th>\n",
       "      <th>date_agg__review_quarter</th>\n",
       "      <th>remainder__stars</th>\n",
       "      <th>remainder__is_open</th>\n",
       "      <th>str_agg__avg_text_length_per_category</th>\n",
       "      <th>str_agg__std_text_length_per_category</th>\n",
       "      <th>str_agg__relative_length</th>\n",
       "      <th>str_agg__text_clean_emb_0</th>\n",
       "      <th>str_agg__text_clean_emb_1</th>\n",
       "      <th>str_agg__text_clean_emb_2</th>\n",
       "      <th>str_agg__text_clean_emb_3</th>\n",
       "      <th>str_agg__text_clean_emb_4</th>\n",
       "      <th>str_agg__text_clean_emb_5</th>\n",
       "      <th>str_agg__text_clean_emb_6</th>\n",
       "      <th>str_agg__text_clean_emb_7</th>\n",
       "      <th>str_agg__text_clean_emb_8</th>\n",
       "      <th>str_agg__text_clean_emb_9</th>\n",
       "      <th>str_agg__text_clean_emb_10</th>\n",
       "      <th>str_agg__text_clean_emb_11</th>\n",
       "      <th>str_agg__text_clean_emb_12</th>\n",
       "      <th>str_agg__text_clean_emb_13</th>\n",
       "      <th>str_agg__text_clean_emb_14</th>\n",
       "      <th>str_agg__text_clean_emb_15</th>\n",
       "      <th>str_agg__text_clean_emb_16</th>\n",
       "      <th>str_agg__text_clean_emb_17</th>\n",
       "      <th>str_agg__text_clean_emb_18</th>\n",
       "      <th>str_agg__text_clean_emb_19</th>\n",
       "      <th>str_agg__text_clean_emb_20</th>\n",
       "      <th>str_agg__text_clean_emb_21</th>\n",
       "      <th>str_agg__text_clean_emb_22</th>\n",
       "      <th>str_agg__text_clean_emb_23</th>\n",
       "      <th>str_agg__text_clean_emb_24</th>\n",
       "      <th>str_agg__text_clean_emb_25</th>\n",
       "      <th>str_agg__text_clean_emb_26</th>\n",
       "      <th>str_agg__text_clean_emb_27</th>\n",
       "      <th>str_agg__text_clean_emb_28</th>\n",
       "      <th>str_agg__text_clean_emb_29</th>\n",
       "      <th>str_agg__text_clean_emb_30</th>\n",
       "      <th>str_agg__text_clean_emb_31</th>\n",
       "      <th>str_agg__text_clean_emb_32</th>\n",
       "      <th>str_agg__text_clean_emb_33</th>\n",
       "      <th>str_agg__text_clean_emb_34</th>\n",
       "      <th>str_agg__text_clean_emb_35</th>\n",
       "      <th>str_agg__text_clean_emb_36</th>\n",
       "      <th>str_agg__text_clean_emb_37</th>\n",
       "      <th>str_agg__text_clean_emb_38</th>\n",
       "      <th>str_agg__text_clean_emb_39</th>\n",
       "      <th>str_agg__text_clean_emb_40</th>\n",
       "      <th>str_agg__text_clean_emb_41</th>\n",
       "      <th>str_agg__text_clean_emb_42</th>\n",
       "      <th>str_agg__text_clean_emb_43</th>\n",
       "      <th>str_agg__text_clean_emb_44</th>\n",
       "      <th>str_agg__text_clean_emb_45</th>\n",
       "      <th>str_agg__text_clean_emb_46</th>\n",
       "      <th>str_agg__text_clean_emb_47</th>\n",
       "      <th>str_agg__text_clean_emb_48</th>\n",
       "      <th>str_agg__text_clean_emb_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>282552</th>\n",
       "      <td>0</td>\n",
       "      <td>0.056547</td>\n",
       "      <td>0.078030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>346</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>639.955566</td>\n",
       "      <td>532.742432</td>\n",
       "      <td>-293.955597</td>\n",
       "      <td>0.073381</td>\n",
       "      <td>0.401102</td>\n",
       "      <td>0.238601</td>\n",
       "      <td>0.061477</td>\n",
       "      <td>-0.044338</td>\n",
       "      <td>-0.154241</td>\n",
       "      <td>-0.011340</td>\n",
       "      <td>-0.018620</td>\n",
       "      <td>0.289003</td>\n",
       "      <td>-0.084832</td>\n",
       "      <td>-0.291393</td>\n",
       "      <td>0.558012</td>\n",
       "      <td>0.213976</td>\n",
       "      <td>0.229256</td>\n",
       "      <td>0.036858</td>\n",
       "      <td>-0.211612</td>\n",
       "      <td>-0.336396</td>\n",
       "      <td>0.123942</td>\n",
       "      <td>0.200076</td>\n",
       "      <td>-0.098444</td>\n",
       "      <td>0.363149</td>\n",
       "      <td>-1.003926</td>\n",
       "      <td>-0.279715</td>\n",
       "      <td>-0.598841</td>\n",
       "      <td>0.461337</td>\n",
       "      <td>0.230579</td>\n",
       "      <td>-0.297323</td>\n",
       "      <td>-0.789541</td>\n",
       "      <td>-0.111303</td>\n",
       "      <td>-0.123873</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>-0.398230</td>\n",
       "      <td>0.526760</td>\n",
       "      <td>0.312817</td>\n",
       "      <td>-0.963278</td>\n",
       "      <td>-0.420191</td>\n",
       "      <td>-0.130453</td>\n",
       "      <td>-0.353203</td>\n",
       "      <td>-0.191510</td>\n",
       "      <td>-0.441183</td>\n",
       "      <td>0.451394</td>\n",
       "      <td>-0.734811</td>\n",
       "      <td>-0.147773</td>\n",
       "      <td>0.023153</td>\n",
       "      <td>0.362523</td>\n",
       "      <td>0.084307</td>\n",
       "      <td>-0.174078</td>\n",
       "      <td>-0.388001</td>\n",
       "      <td>0.231893</td>\n",
       "      <td>0.410410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471743</th>\n",
       "      <td>6</td>\n",
       "      <td>0.035001</td>\n",
       "      <td>0.045575</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>658</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>544</td>\n",
       "      <td>98</td>\n",
       "      <td>False</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>639.955566</td>\n",
       "      <td>532.742432</td>\n",
       "      <td>-95.955597</td>\n",
       "      <td>-0.079024</td>\n",
       "      <td>0.464177</td>\n",
       "      <td>0.021083</td>\n",
       "      <td>-0.682393</td>\n",
       "      <td>-0.103070</td>\n",
       "      <td>0.104121</td>\n",
       "      <td>0.175629</td>\n",
       "      <td>-0.089554</td>\n",
       "      <td>0.404134</td>\n",
       "      <td>-0.168858</td>\n",
       "      <td>-0.230274</td>\n",
       "      <td>0.070082</td>\n",
       "      <td>-0.170812</td>\n",
       "      <td>-0.149579</td>\n",
       "      <td>0.170631</td>\n",
       "      <td>-0.607221</td>\n",
       "      <td>-0.091658</td>\n",
       "      <td>0.069804</td>\n",
       "      <td>-0.234350</td>\n",
       "      <td>-0.307690</td>\n",
       "      <td>-0.113724</td>\n",
       "      <td>-0.780718</td>\n",
       "      <td>-0.481394</td>\n",
       "      <td>-0.428563</td>\n",
       "      <td>0.033801</td>\n",
       "      <td>0.028850</td>\n",
       "      <td>0.257760</td>\n",
       "      <td>-0.358517</td>\n",
       "      <td>-0.503118</td>\n",
       "      <td>-0.310148</td>\n",
       "      <td>-0.465773</td>\n",
       "      <td>-0.316208</td>\n",
       "      <td>0.260485</td>\n",
       "      <td>-0.313596</td>\n",
       "      <td>0.594308</td>\n",
       "      <td>-0.121240</td>\n",
       "      <td>-0.115578</td>\n",
       "      <td>-0.154527</td>\n",
       "      <td>0.324453</td>\n",
       "      <td>-0.011011</td>\n",
       "      <td>0.209795</td>\n",
       "      <td>-0.094523</td>\n",
       "      <td>-0.252922</td>\n",
       "      <td>0.043142</td>\n",
       "      <td>-0.008492</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>-0.175689</td>\n",
       "      <td>-0.109226</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.043367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651872</th>\n",
       "      <td>5</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.183707</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>393</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1060</td>\n",
       "      <td>201</td>\n",
       "      <td>True</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>5</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>639.955566</td>\n",
       "      <td>532.742432</td>\n",
       "      <td>420.044403</td>\n",
       "      <td>-0.374734</td>\n",
       "      <td>0.317017</td>\n",
       "      <td>0.019842</td>\n",
       "      <td>-0.302896</td>\n",
       "      <td>-0.473648</td>\n",
       "      <td>0.073524</td>\n",
       "      <td>0.299914</td>\n",
       "      <td>0.046909</td>\n",
       "      <td>0.394122</td>\n",
       "      <td>0.524828</td>\n",
       "      <td>-0.064547</td>\n",
       "      <td>-0.057209</td>\n",
       "      <td>-0.164429</td>\n",
       "      <td>-0.320499</td>\n",
       "      <td>-0.021354</td>\n",
       "      <td>0.667428</td>\n",
       "      <td>-0.059192</td>\n",
       "      <td>-0.457868</td>\n",
       "      <td>0.182565</td>\n",
       "      <td>-0.245590</td>\n",
       "      <td>0.007257</td>\n",
       "      <td>-0.366044</td>\n",
       "      <td>-0.026976</td>\n",
       "      <td>-0.241783</td>\n",
       "      <td>0.202669</td>\n",
       "      <td>0.663131</td>\n",
       "      <td>0.517704</td>\n",
       "      <td>-0.432478</td>\n",
       "      <td>-0.215998</td>\n",
       "      <td>-0.250849</td>\n",
       "      <td>-0.238095</td>\n",
       "      <td>0.551950</td>\n",
       "      <td>-0.105194</td>\n",
       "      <td>0.177197</td>\n",
       "      <td>0.845513</td>\n",
       "      <td>0.016410</td>\n",
       "      <td>0.287799</td>\n",
       "      <td>-0.399746</td>\n",
       "      <td>-0.206951</td>\n",
       "      <td>-0.188451</td>\n",
       "      <td>-0.096079</td>\n",
       "      <td>-0.133126</td>\n",
       "      <td>-0.203529</td>\n",
       "      <td>-0.724825</td>\n",
       "      <td>-0.013907</td>\n",
       "      <td>-0.230514</td>\n",
       "      <td>-0.345582</td>\n",
       "      <td>-0.489120</td>\n",
       "      <td>-0.399413</td>\n",
       "      <td>-0.149543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361024</th>\n",
       "      <td>0</td>\n",
       "      <td>0.113044</td>\n",
       "      <td>0.200348</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>639.955566</td>\n",
       "      <td>532.742432</td>\n",
       "      <td>-314.955597</td>\n",
       "      <td>-0.180681</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>-0.103990</td>\n",
       "      <td>-0.731153</td>\n",
       "      <td>-0.026752</td>\n",
       "      <td>0.253059</td>\n",
       "      <td>0.671096</td>\n",
       "      <td>-0.216157</td>\n",
       "      <td>-0.032670</td>\n",
       "      <td>-0.314932</td>\n",
       "      <td>-0.146187</td>\n",
       "      <td>-0.293769</td>\n",
       "      <td>0.035029</td>\n",
       "      <td>0.140799</td>\n",
       "      <td>-0.205075</td>\n",
       "      <td>-0.139843</td>\n",
       "      <td>-0.684210</td>\n",
       "      <td>0.080507</td>\n",
       "      <td>0.571595</td>\n",
       "      <td>-0.308306</td>\n",
       "      <td>-0.120389</td>\n",
       "      <td>-0.626092</td>\n",
       "      <td>0.530713</td>\n",
       "      <td>-0.465187</td>\n",
       "      <td>0.035872</td>\n",
       "      <td>-0.364389</td>\n",
       "      <td>0.346865</td>\n",
       "      <td>-0.521696</td>\n",
       "      <td>0.127112</td>\n",
       "      <td>-0.541459</td>\n",
       "      <td>-0.210797</td>\n",
       "      <td>-0.133499</td>\n",
       "      <td>0.643843</td>\n",
       "      <td>0.047296</td>\n",
       "      <td>-0.004573</td>\n",
       "      <td>-0.372940</td>\n",
       "      <td>0.043371</td>\n",
       "      <td>-0.083215</td>\n",
       "      <td>0.096944</td>\n",
       "      <td>-0.196300</td>\n",
       "      <td>0.771172</td>\n",
       "      <td>-0.360444</td>\n",
       "      <td>-0.485713</td>\n",
       "      <td>-0.190156</td>\n",
       "      <td>0.134873</td>\n",
       "      <td>-0.076158</td>\n",
       "      <td>-0.373300</td>\n",
       "      <td>-0.131175</td>\n",
       "      <td>0.112931</td>\n",
       "      <td>-0.230301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512239</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113044</td>\n",
       "      <td>0.200348</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>318</td>\n",
       "      <td>59</td>\n",
       "      <td>True</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>13</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>639.955566</td>\n",
       "      <td>532.742432</td>\n",
       "      <td>-321.955597</td>\n",
       "      <td>-0.013276</td>\n",
       "      <td>0.533177</td>\n",
       "      <td>0.338198</td>\n",
       "      <td>-0.579823</td>\n",
       "      <td>-0.264113</td>\n",
       "      <td>-0.436391</td>\n",
       "      <td>0.654914</td>\n",
       "      <td>-0.359485</td>\n",
       "      <td>0.230481</td>\n",
       "      <td>-0.031154</td>\n",
       "      <td>-0.437090</td>\n",
       "      <td>-0.254600</td>\n",
       "      <td>-0.178335</td>\n",
       "      <td>-0.164152</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>-0.489766</td>\n",
       "      <td>-0.122146</td>\n",
       "      <td>0.214201</td>\n",
       "      <td>0.390073</td>\n",
       "      <td>-0.201521</td>\n",
       "      <td>0.059544</td>\n",
       "      <td>-0.515621</td>\n",
       "      <td>-0.167281</td>\n",
       "      <td>-0.341711</td>\n",
       "      <td>-0.107389</td>\n",
       "      <td>0.279075</td>\n",
       "      <td>0.346947</td>\n",
       "      <td>-0.890139</td>\n",
       "      <td>-0.219980</td>\n",
       "      <td>0.059269</td>\n",
       "      <td>-0.655289</td>\n",
       "      <td>0.081459</td>\n",
       "      <td>0.233596</td>\n",
       "      <td>-0.045654</td>\n",
       "      <td>0.701849</td>\n",
       "      <td>-0.106562</td>\n",
       "      <td>0.604701</td>\n",
       "      <td>-0.292542</td>\n",
       "      <td>-0.118461</td>\n",
       "      <td>-0.295983</td>\n",
       "      <td>0.169136</td>\n",
       "      <td>-0.140318</td>\n",
       "      <td>0.423756</td>\n",
       "      <td>-0.121397</td>\n",
       "      <td>0.242513</td>\n",
       "      <td>0.169317</td>\n",
       "      <td>-0.109272</td>\n",
       "      <td>-0.137999</td>\n",
       "      <td>0.103012</td>\n",
       "      <td>-0.100314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat_agg__elite_count  cat_agg__city_freq  cat_agg__state_freq  \\\n",
       "282552                     0            0.056547             0.078030   \n",
       "471743                     6            0.035001             0.045575   \n",
       "651872                     5            0.008482             0.183707   \n",
       "361024                     0            0.113044             0.200348   \n",
       "512239                     1            0.113044             0.200348   \n",
       "\n",
       "        num_agg__useful  num_agg__funny  num_agg__cool  num_agg__review_count  \\\n",
       "282552                1               0              0                     84   \n",
       "471743                1               2              1                    658   \n",
       "651872                1               2              1                    393   \n",
       "361024                1               0              1                      4   \n",
       "512239                1               0              0                     75   \n",
       "\n",
       "        num_agg__is_useful  num_agg__is_funny  num_agg__is_cool  \\\n",
       "282552                True              False             False   \n",
       "471743                True               True              True   \n",
       "651872                True               True              True   \n",
       "361024                True              False              True   \n",
       "512239                True              False             False   \n",
       "\n",
       "        num_agg__review_count_level  num_agg__useful_user_level  \\\n",
       "282552                            2                           1   \n",
       "471743                            3                           3   \n",
       "651872                            3                           3   \n",
       "361024                            0                           0   \n",
       "512239                            2                           2   \n",
       "\n",
       "        num_agg__funny_user_level  num_agg__cool_user_level  \\\n",
       "282552                          1                         1   \n",
       "471743                          3                         3   \n",
       "651872                          3                         3   \n",
       "361024                          0                         0   \n",
       "512239                          2                         2   \n",
       "\n",
       "        num_agg__fans_level  str_agg__text_length  str_agg__word_count  \\\n",
       "282552                    1                   346                   57   \n",
       "471743                    2                   544                   98   \n",
       "651872                    1                  1060                  201   \n",
       "361024                    0                   325                   52   \n",
       "512239                    1                   318                   59   \n",
       "\n",
       "        str_agg__has_exclamation str_agg__main_category_group  \\\n",
       "282552                     False                   restaurant   \n",
       "471743                     False                   restaurant   \n",
       "651872                      True                   restaurant   \n",
       "361024                      True                   restaurant   \n",
       "512239                      True                   restaurant   \n",
       "\n",
       "        str_agg__category_count  date_agg__review_year  \\\n",
       "282552                        4                   2020   \n",
       "471743                        7                   2019   \n",
       "651872                        5                   2019   \n",
       "361024                        4                   2020   \n",
       "512239                       13                   2019   \n",
       "\n",
       "        date_agg__review_month  date_agg__review_dayofweek  \\\n",
       "282552                      10                           3   \n",
       "471743                      12                           0   \n",
       "651872                       6                           0   \n",
       "361024                       5                           3   \n",
       "512239                      10                           1   \n",
       "\n",
       "        date_agg__is_weekend  date_agg__review_quarter  remainder__stars  \\\n",
       "282552                 False                         4                 5   \n",
       "471743                 False                         4                 5   \n",
       "651872                 False                         2                 2   \n",
       "361024                 False                         2                 5   \n",
       "512239                 False                         4                 5   \n",
       "\n",
       "        remainder__is_open  str_agg__avg_text_length_per_category  \\\n",
       "282552                True                             639.955566   \n",
       "471743                True                             639.955566   \n",
       "651872                True                             639.955566   \n",
       "361024                True                             639.955566   \n",
       "512239                True                             639.955566   \n",
       "\n",
       "        str_agg__std_text_length_per_category  str_agg__relative_length  \\\n",
       "282552                             532.742432               -293.955597   \n",
       "471743                             532.742432                -95.955597   \n",
       "651872                             532.742432                420.044403   \n",
       "361024                             532.742432               -314.955597   \n",
       "512239                             532.742432               -321.955597   \n",
       "\n",
       "        str_agg__text_clean_emb_0  str_agg__text_clean_emb_1  \\\n",
       "282552                   0.073381                   0.401102   \n",
       "471743                  -0.079024                   0.464177   \n",
       "651872                  -0.374734                   0.317017   \n",
       "361024                  -0.180681                   0.023614   \n",
       "512239                  -0.013276                   0.533177   \n",
       "\n",
       "        str_agg__text_clean_emb_2  str_agg__text_clean_emb_3  \\\n",
       "282552                   0.238601                   0.061477   \n",
       "471743                   0.021083                  -0.682393   \n",
       "651872                   0.019842                  -0.302896   \n",
       "361024                  -0.103990                  -0.731153   \n",
       "512239                   0.338198                  -0.579823   \n",
       "\n",
       "        str_agg__text_clean_emb_4  str_agg__text_clean_emb_5  \\\n",
       "282552                  -0.044338                  -0.154241   \n",
       "471743                  -0.103070                   0.104121   \n",
       "651872                  -0.473648                   0.073524   \n",
       "361024                  -0.026752                   0.253059   \n",
       "512239                  -0.264113                  -0.436391   \n",
       "\n",
       "        str_agg__text_clean_emb_6  str_agg__text_clean_emb_7  \\\n",
       "282552                  -0.011340                  -0.018620   \n",
       "471743                   0.175629                  -0.089554   \n",
       "651872                   0.299914                   0.046909   \n",
       "361024                   0.671096                  -0.216157   \n",
       "512239                   0.654914                  -0.359485   \n",
       "\n",
       "        str_agg__text_clean_emb_8  str_agg__text_clean_emb_9  \\\n",
       "282552                   0.289003                  -0.084832   \n",
       "471743                   0.404134                  -0.168858   \n",
       "651872                   0.394122                   0.524828   \n",
       "361024                  -0.032670                  -0.314932   \n",
       "512239                   0.230481                  -0.031154   \n",
       "\n",
       "        str_agg__text_clean_emb_10  str_agg__text_clean_emb_11  \\\n",
       "282552                   -0.291393                    0.558012   \n",
       "471743                   -0.230274                    0.070082   \n",
       "651872                   -0.064547                   -0.057209   \n",
       "361024                   -0.146187                   -0.293769   \n",
       "512239                   -0.437090                   -0.254600   \n",
       "\n",
       "        str_agg__text_clean_emb_12  str_agg__text_clean_emb_13  \\\n",
       "282552                    0.213976                    0.229256   \n",
       "471743                   -0.170812                   -0.149579   \n",
       "651872                   -0.164429                   -0.320499   \n",
       "361024                    0.035029                    0.140799   \n",
       "512239                   -0.178335                   -0.164152   \n",
       "\n",
       "        str_agg__text_clean_emb_14  str_agg__text_clean_emb_15  \\\n",
       "282552                    0.036858                   -0.211612   \n",
       "471743                    0.170631                   -0.607221   \n",
       "651872                   -0.021354                    0.667428   \n",
       "361024                   -0.205075                   -0.139843   \n",
       "512239                    0.020317                   -0.489766   \n",
       "\n",
       "        str_agg__text_clean_emb_16  str_agg__text_clean_emb_17  \\\n",
       "282552                   -0.336396                    0.123942   \n",
       "471743                   -0.091658                    0.069804   \n",
       "651872                   -0.059192                   -0.457868   \n",
       "361024                   -0.684210                    0.080507   \n",
       "512239                   -0.122146                    0.214201   \n",
       "\n",
       "        str_agg__text_clean_emb_18  str_agg__text_clean_emb_19  \\\n",
       "282552                    0.200076                   -0.098444   \n",
       "471743                   -0.234350                   -0.307690   \n",
       "651872                    0.182565                   -0.245590   \n",
       "361024                    0.571595                   -0.308306   \n",
       "512239                    0.390073                   -0.201521   \n",
       "\n",
       "        str_agg__text_clean_emb_20  str_agg__text_clean_emb_21  \\\n",
       "282552                    0.363149                   -1.003926   \n",
       "471743                   -0.113724                   -0.780718   \n",
       "651872                    0.007257                   -0.366044   \n",
       "361024                   -0.120389                   -0.626092   \n",
       "512239                    0.059544                   -0.515621   \n",
       "\n",
       "        str_agg__text_clean_emb_22  str_agg__text_clean_emb_23  \\\n",
       "282552                   -0.279715                   -0.598841   \n",
       "471743                   -0.481394                   -0.428563   \n",
       "651872                   -0.026976                   -0.241783   \n",
       "361024                    0.530713                   -0.465187   \n",
       "512239                   -0.167281                   -0.341711   \n",
       "\n",
       "        str_agg__text_clean_emb_24  str_agg__text_clean_emb_25  \\\n",
       "282552                    0.461337                    0.230579   \n",
       "471743                    0.033801                    0.028850   \n",
       "651872                    0.202669                    0.663131   \n",
       "361024                    0.035872                   -0.364389   \n",
       "512239                   -0.107389                    0.279075   \n",
       "\n",
       "        str_agg__text_clean_emb_26  str_agg__text_clean_emb_27  \\\n",
       "282552                   -0.297323                   -0.789541   \n",
       "471743                    0.257760                   -0.358517   \n",
       "651872                    0.517704                   -0.432478   \n",
       "361024                    0.346865                   -0.521696   \n",
       "512239                    0.346947                   -0.890139   \n",
       "\n",
       "        str_agg__text_clean_emb_28  str_agg__text_clean_emb_29  \\\n",
       "282552                   -0.111303                   -0.123873   \n",
       "471743                   -0.503118                   -0.310148   \n",
       "651872                   -0.215998                   -0.250849   \n",
       "361024                    0.127112                   -0.541459   \n",
       "512239                   -0.219980                    0.059269   \n",
       "\n",
       "        str_agg__text_clean_emb_30  str_agg__text_clean_emb_31  \\\n",
       "282552                    0.005592                   -0.398230   \n",
       "471743                   -0.465773                   -0.316208   \n",
       "651872                   -0.238095                    0.551950   \n",
       "361024                   -0.210797                   -0.133499   \n",
       "512239                   -0.655289                    0.081459   \n",
       "\n",
       "        str_agg__text_clean_emb_32  str_agg__text_clean_emb_33  \\\n",
       "282552                    0.526760                    0.312817   \n",
       "471743                    0.260485                   -0.313596   \n",
       "651872                   -0.105194                    0.177197   \n",
       "361024                    0.643843                    0.047296   \n",
       "512239                    0.233596                   -0.045654   \n",
       "\n",
       "        str_agg__text_clean_emb_34  str_agg__text_clean_emb_35  \\\n",
       "282552                   -0.963278                   -0.420191   \n",
       "471743                    0.594308                   -0.121240   \n",
       "651872                    0.845513                    0.016410   \n",
       "361024                   -0.004573                   -0.372940   \n",
       "512239                    0.701849                   -0.106562   \n",
       "\n",
       "        str_agg__text_clean_emb_36  str_agg__text_clean_emb_37  \\\n",
       "282552                   -0.130453                   -0.353203   \n",
       "471743                   -0.115578                   -0.154527   \n",
       "651872                    0.287799                   -0.399746   \n",
       "361024                    0.043371                   -0.083215   \n",
       "512239                    0.604701                   -0.292542   \n",
       "\n",
       "        str_agg__text_clean_emb_38  str_agg__text_clean_emb_39  \\\n",
       "282552                   -0.191510                   -0.441183   \n",
       "471743                    0.324453                   -0.011011   \n",
       "651872                   -0.206951                   -0.188451   \n",
       "361024                    0.096944                   -0.196300   \n",
       "512239                   -0.118461                   -0.295983   \n",
       "\n",
       "        str_agg__text_clean_emb_40  str_agg__text_clean_emb_41  \\\n",
       "282552                    0.451394                   -0.734811   \n",
       "471743                    0.209795                   -0.094523   \n",
       "651872                   -0.096079                   -0.133126   \n",
       "361024                    0.771172                   -0.360444   \n",
       "512239                    0.169136                   -0.140318   \n",
       "\n",
       "        str_agg__text_clean_emb_42  str_agg__text_clean_emb_43  \\\n",
       "282552                   -0.147773                    0.023153   \n",
       "471743                   -0.252922                    0.043142   \n",
       "651872                   -0.203529                   -0.724825   \n",
       "361024                   -0.485713                   -0.190156   \n",
       "512239                    0.423756                   -0.121397   \n",
       "\n",
       "        str_agg__text_clean_emb_44  str_agg__text_clean_emb_45  \\\n",
       "282552                    0.362523                    0.084307   \n",
       "471743                   -0.008492                    0.022023   \n",
       "651872                   -0.013907                   -0.230514   \n",
       "361024                    0.134873                   -0.076158   \n",
       "512239                    0.242513                    0.169317   \n",
       "\n",
       "        str_agg__text_clean_emb_46  str_agg__text_clean_emb_47  \\\n",
       "282552                   -0.174078                   -0.388001   \n",
       "471743                   -0.175689                   -0.109226   \n",
       "651872                   -0.345582                   -0.489120   \n",
       "361024                   -0.373300                   -0.131175   \n",
       "512239                   -0.109272                   -0.137999   \n",
       "\n",
       "        str_agg__text_clean_emb_48  str_agg__text_clean_emb_49  \n",
       "282552                    0.231893                    0.410410  \n",
       "471743                    0.000681                    0.043367  \n",
       "651872                   -0.399413                   -0.149543  \n",
       "361024                    0.112931                   -0.230301  \n",
       "512239                    0.103012                   -0.100314  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_BCoR-1rUpb",
    "outputId": "09eb8e44-1955-416b-ea53-1a8f132d99a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000066, 80)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float32     53\n",
       "int32       16\n",
       "bool         6\n",
       "float64      2\n",
       "int64        2\n",
       "category     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yot8MOibnA6N"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DropColumnsTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns, errors=\"ignore\")\n",
    "\n",
    "    def set_output(self, *, transform=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TargetFromStarsTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetFromStarsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column=\"remainder__stars\"):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "\n",
    "        def classify(stars):\n",
    "            if stars <= 2:\n",
    "                return 0  # negative\n",
    "            elif stars == 3:\n",
    "                return 1  # neutral\n",
    "            else:\n",
    "                return 2  # positive\n",
    "\n",
    "        X[\"target\"] = X[self.column].apply(classify)\n",
    "        X.drop(columns=[self.column], inplace=True)\n",
    "        return X\n",
    "\n",
    "    def set_output(self, *, transform=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_target_pipe = Pipeline(\n",
    "    [\n",
    "        (\"create_target\", TargetFromStarsTransformer(column=\"remainder__stars\")),\n",
    "        (\"drop_stars\", DropColumnsTransformer(columns=[\"remainder__stars\"])),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = create_target_pipe.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target_column=\"target\", test_size=0.2, random_state=42):\n",
    "    y = df[target_column]\n",
    "    X = df.drop(columns=[target_column])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        X_train.reset_index(drop=True),\n",
    "        X_test.reset_index(drop=True),\n",
    "        y_train.reset_index(drop=True),\n",
    "        y_test.reset_index(drop=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Dependent Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_with_names(pipeline, X, encode_cols):\n",
    "    X_enc = pipeline.transform(X)\n",
    "    onehot_cols = pipeline.named_transformers_[\"onehot\"].get_feature_names_out(\n",
    "        encode_cols\n",
    "    )\n",
    "    bool_cols = pipeline.transformers_[1][2]\n",
    "    passthrough_cols = [col for col in X.columns if col not in encode_cols + bool_cols]\n",
    "\n",
    "    all_columns = list(onehot_cols) + bool_cols + passthrough_cols\n",
    "    return pd.DataFrame(X_enc, columns=all_columns, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_str_object_cols = X_train.select_dtypes(\n",
    "    include=[\"category\", \"string\", \"object\"]\n",
    ").columns.tolist()\n",
    "boolean_cols = X_train.select_dtypes(include=[\"bool\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Step\n",
    "bool_to_int_transformer = FunctionTransformer(\n",
    "    lambda X: X.astype(np.int8), validate=False\n",
    ")\n",
    "\n",
    "# 2. Step\n",
    "encoding_mdt_pipe = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\n",
    "            \"onehot\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\"),\n",
    "            categorical_str_object_cols,\n",
    "        ),\n",
    "        (\"bool_int\", bool_to_int_transformer, boolean_cols),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    "    force_int_remainder_cols=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Encoding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding_mdt_pipe.fit(X_train)\n",
    "# X_train_encoded = transform_with_names(\n",
    "#     encoding_mdt_pipe, X_train, categorical_str_object_cols\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupMeanImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.group_means_ = {}\n",
    "        self.y_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = pd.DataFrame(X).copy()\n",
    "        self.y_ = pd.Series(y).reset_index(drop=True)\n",
    "\n",
    "        self.group_means_ = {\n",
    "            col: X[col].groupby(self.y_).mean().to_dict() for col in self.columns\n",
    "        }\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X).copy().reset_index(drop=True)\n",
    "        y = self.y_\n",
    "\n",
    "        for col in self.columns:\n",
    "            means = self.group_means_[col]\n",
    "            X[col] = X[col].where(~X[col].isna(), y.map(means))\n",
    "        return X\n",
    "\n",
    "    def set_output(self, *, transform=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_with_na(X):\n",
    "    return X.columns[X.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_with_na = get_columns_with_na(df)\n",
    "\n",
    "impute_missing_mdt_pipe = Pipeline(\n",
    "    [(\"imputation\", GroupMeanImputer(columns=columns_with_na))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Impute missing values Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_imputed = impute_missing_mdt_pipe.fit_transform(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale or normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_mdt_pipe = Pipeline([(\"minmax_scaler\", MinMaxScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scale or normalize features Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_scaled1 = scaling_mdt_pipe.fit_transform(X_train_imputed)\n",
    "# X_train_scaled = pd.DataFrame(\n",
    "#     X_train_scaled1, columns=X_train_imputed.columns, index=X_train_imputed.index\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality_reduction_mdt_pipe = Pipeline(\n",
    "    [\n",
    "        (\"drop_constant\", DropConstantFeatures()),\n",
    "        (\"drop_correlated\", DropCorrelatedFeatures(threshold=0.9)),\n",
    "        (\n",
    "            \"target_selector\",\n",
    "            SelectBySingleFeaturePerformance(\n",
    "                estimator=RandomForestClassifier(\n",
    "                    n_estimators=50, random_state=42, n_jobs=-1\n",
    "                ),\n",
    "                scoring=\"f1_weighted\",\n",
    "                cv=3,\n",
    "                threshold=0.01,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"sequential_selector\",\n",
    "            SequentialFeatureSelector(\n",
    "                estimator=RidgeClassifier(),\n",
    "                n_features_to_select=50,\n",
    "                direction=\"forward\",\n",
    "                n_jobs=1,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dimensionality reduction Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_train_reduced = dimensionality_reduction_mdt_pipe.fit_transform(\n",
    "#     X_train_scaled, y_train\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_reduced_df = pd.DataFrame(\n",
    "#     X_train_reduced,\n",
    "#     columns=dimensionality_reduction_mdt_pipe.named_steps[\n",
    "#         \"sequential_selector\"\n",
    "#     ].get_feature_names_out(),\n",
    "#     index=X_train_scaled.index,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdt_preprocessor = Pipeline(\n",
    "    steps=[\n",
    "        (\"encoding_mdt_pipe\", encoding_mdt_pipe),\n",
    "        (\"impute_missing_mdt_pipe\", impute_missing_mdt_pipe),\n",
    "        (\"scaling_mdt_pipe\", scaling_mdt_pipe),\n",
    "        (\"dimensionality_reduction_mdt_pipe\", dimensionality_reduction_mdt_pipe),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = pd.read_parquet(BASE_DIR / \"data/05_model_input/x_train.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base model + AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def summarize_classification(y_true, y_pred, model_name):\n",
    "#     return {\n",
    "#         \"model\": model_name,\n",
    "#         \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "#         \"precision_macro\": precision_score(y_true, y_pred, average=\"macro\"),\n",
    "#         \"recall_macro\": recall_score(y_true, y_pred, average=\"macro\"),\n",
    "#         \"f1_macro\": f1_score(y_true, y_pred, average=\"macro\"),\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_models = X_train_reduced.copy()\n",
    "# df_models[\"target\"] = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_cv, X_val_cv, y_train_cv, y_val_cv = split_data(df_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_candidates = {\n",
    "#     \"logistic\": LogisticRegression(class_weight=\"balanced\", max_iter=1000, random_state=42),\n",
    "#     \"decision_tree\": DecisionTreeClassifier(class_weight=\"balanced\", random_state=42),\n",
    "#     \"xgboost\": XGBClassifier(\n",
    "#         objective=\"multi:softmax\",\n",
    "#         num_class=3,\n",
    "#         eval_metric=\"mlogloss\",\n",
    "#         use_label_encoder=False,\n",
    "#         random_state=42,\n",
    "#         verbosity=0,\n",
    "#     )\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, model in model_candidates.items():\n",
    "#     model.fit(X_train_cv, y_train_cv)\n",
    "#     y_pred = model.predict(X_val_cv)\n",
    "#     results.append(summarize_classification(y_val_cv, y_pred, model_name=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# automl = AutoML()\n",
    "# automl.fit(\n",
    "#     X_train=X_train_cv, y_train=y_train_cv, task=\"classification\", time_budget=60\n",
    "# )\n",
    "# y_pred_automl = automl.predict(X_val_cv)\n",
    "# results.append(summarize_classification(y_val_cv, y_pred_automl, model_name=\"flaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = pd.DataFrame(results).set_index(\"model\")\n",
    "# display(results_df.sort_values(\"f1_macro\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_grid_search(model, param_grid, X, y, scoring=\"f1_macro\", cv=5, verbose=1):\n",
    "#     return GridSearchCV(\n",
    "#         estimator=model,\n",
    "#         param_grid=param_grid,\n",
    "#         scoring=scoring,\n",
    "#         cv=cv,\n",
    "#         n_jobs=-1,\n",
    "#         return_train_score=True,\n",
    "#         verbose=verbose,\n",
    "#     ).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def summarize_grid_search(grid, scoring=\"f1_macro\"):\n",
    "#     print(f\"Best {scoring}: {grid.best_score_:.4f}\")\n",
    "#     print(f\"Best params: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def grid_search_to_df(grid):\n",
    "#     return pd.DataFrame(grid.cv_results_).sort_values(\n",
    "#         \"mean_test_score\", ascending=False\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier(\n",
    "#     objective=\"multi:softmax\",\n",
    "#     num_class=3,\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric=\"mlogloss\",\n",
    "#     random_state=42,\n",
    "#     verbosity=0,\n",
    "# )\n",
    "\n",
    "# param_grid = {\n",
    "#     \"max_depth\": [3, 5, 7],\n",
    "#     \"learning_rate\": [0.01, 0.1, 0.3],\n",
    "#     \"n_estimators\": [50, 100],\n",
    "#     \"subsample\": [0.8, 1.0],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 1: training\n",
    "# grid = fit_grid_search(model, param_grid, X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 2: summary\n",
    "# summarize_grid_search(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 3: df results\n",
    "# df_grid = grid_search_to_df(grid)\n",
    "# df_grid.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_name_path = BASE_DIR / \"data/06_models/best_model_name.txt\"\n",
    "# with open(best_model_name_path, \"w\") as f:\n",
    "#     f.write(\"XGBClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_path = BASE_DIR / \"data/06_models/best_params.json\"\n",
    "# with open(best_params_path, \"w\") as f:\n",
    "#     json.dump(grid.best_params_, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline final training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_fn = best_model_name_path.read_text().strip()\n",
    "with open(best_params_path) as f:\n",
    "    best_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModelTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, classifier_fn, best_params):\n",
    "        self.classifier_fn = classifier_fn\n",
    "        self.best_params = best_params\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model_ = self.classifier_fn(**self.best_params)\n",
    "        self.model_.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X\n",
    "\n",
    "    def set_output(self, *, transform=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_preprocessor = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"train_model\",\n",
    "            TrainModelTransformer(classifier_fn=XGBClassifier, best_params=best_params),\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pipeline final training Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training_preprocessor.fit(X_train_reduced, y_train)\n",
    "model = training_preprocessor.named_steps[\"train_model\"].model_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidateModelTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, y_true, thresholds=None):\n",
    "        self.model = model\n",
    "        self.y_true = y_true\n",
    "        self.thresholds = thresholds or {\"f1_macro\": 0.6}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        y_pred = self.model.predict(X)\n",
    "        self.report_ = classification_report(self.y_true, y_pred, output_dict=True)\n",
    "\n",
    "        for metric, threshold in self.thresholds.items():\n",
    "            score = self.report_[\"macro avg\"].get(metric.replace(\"_macro\", \"\"), None)\n",
    "            if score is not None and score < threshold:\n",
    "                raise ValueError(f\"[FAIL] {metric}={score:.4f} < threshold={threshold}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.model\n",
    "\n",
    "    def set_output(self, *, transform=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_preprocessor = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"validate_model\",\n",
    "            ValidateModelTransformer(\n",
    "                model=model,\n",
    "                y_true=y_test,\n",
    "                thresholds={\"f1_macro\": 0.6, \"recall_macro\": 0.6},\n",
    "            ),\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (ml-message-classifier)",
   "language": "python",
   "name": "ml-message-classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
